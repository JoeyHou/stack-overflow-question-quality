{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "altered-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "developed-leonard",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-leave",
   "metadata": {},
   "source": [
    "# 1. Read in Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "processed-assessment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 15000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../data/raw/train.csv')\n",
    "test = pd.read_csv('../data/raw/valid.csv')\n",
    "\n",
    "train.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "checked-surprise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34552656</td>\n",
       "      <td>Java: Repeat Task Every Random Seconds</td>\n",
       "      <td>&lt;p&gt;I'm already familiar with repeating tasks e...</td>\n",
       "      <td>&lt;java&gt;&lt;repeat&gt;</td>\n",
       "      <td>2016-01-01 00:21:59</td>\n",
       "      <td>LQ_CLOSE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34553034</td>\n",
       "      <td>Why are Java Optionals immutable?</td>\n",
       "      <td>&lt;p&gt;I'd like to understand why Java 8 Optionals...</td>\n",
       "      <td>&lt;java&gt;&lt;optional&gt;</td>\n",
       "      <td>2016-01-01 02:03:20</td>\n",
       "      <td>HQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Id                                   Title  \\\n",
       "0  34552656  Java: Repeat Task Every Random Seconds   \n",
       "1  34553034       Why are Java Optionals immutable?   \n",
       "\n",
       "                                                Body              Tags  \\\n",
       "0  <p>I'm already familiar with repeating tasks e...    <java><repeat>   \n",
       "1  <p>I'd like to understand why Java 8 Optionals...  <java><optional>   \n",
       "\n",
       "          CreationDate         Y  \n",
       "0  2016-01-01 00:21:59  LQ_CLOSE  \n",
       "1  2016-01-01 02:03:20        HQ  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "virtual-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[0].CreationDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "confirmed-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = pd.concat([train, test]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "wanted-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "voluntary-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.query('Y == \"HQ\"').shape[0], test.query('Y == \"HQ\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adaptive-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.query('Y == \"LQ_CLOSE\"').shape[0], test.query('Y == \"LQ_CLOSE\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cooperative-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.query('Y == \"LQ_EDIT\"').shape[0], test.query('Y == \"LQ_CLOSE\"').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-assembly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "scientific-finance",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-token",
   "metadata": {},
   "source": [
    "## 2.1 Check NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "extended-growing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id              0\n",
       "Title           0\n",
       "Body            0\n",
       "Tags            0\n",
       "CreationDate    0\n",
       "Y               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vocational-crawford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id              0\n",
       "Title           0\n",
       "Body            0\n",
       "Tags            0\n",
       "CreationDate    0\n",
       "Y               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-price",
   "metadata": {},
   "source": [
    "## 2.2 Clean Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "headed-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    "    'LQ_CLOSE': 0,\n",
    "    'LQ_EDIT': 1,\n",
    "    'HQ': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "finnish-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cleaned_y'] = train.Y.apply(lambda x: label_dict[x])\n",
    "test['cleaned_y'] = test.Y.apply(lambda x: label_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-england",
   "metadata": {},
   "source": [
    "## 2.3 Clean Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "brown-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title\n",
    "train.Title = train.Title.apply(lambda x: x.lower())\n",
    "test.Title = test.Title.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "occasional-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(string):\n",
    "    word_list = [word.lower() for word in string.split()]\n",
    "    stopwords_list = list(stopwords.words(\"english\"))\n",
    "    for word in word_list:\n",
    "        if word in stopwords_list:\n",
    "            word_list.remove(word)\n",
    "    return ' '.join(word_list)\n",
    "\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Acknowledgement: this function is inspired by the following post:\n",
    "        https://www.kaggle.com/anmolkumar/stack-overflow-eda-bert-model-accuracy-87-6\n",
    "    '''\n",
    "    text = re.sub('\\\\n', ' ', text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub(r'https\\s+|www.\\s+', r'', text)\n",
    "    text = re.sub(r'http\\s+|www.\\s+',r'', text)\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+',' ', text)\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+',' ', text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"\\’\", \"\\'\", text)\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"don\\'t\", \"do not\", text)\n",
    "    text = re.sub(r\"dont\", \"do not\", text)\n",
    "    text = re.sub(r\"n\\’t\", \" not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\’d\", \" would\", text)\n",
    "    text = re.sub(r\"\\d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    text = re.sub(r\"\\n\", \"\", text)\n",
    "    text = re.sub(r\"\\r\", \"\", text)\n",
    "    text = re.sub(r\"[0-9]\", \"digit\", text)\n",
    "    text = re.sub(r\"\\'\", \"\", text)\n",
    "    text = re.sub(r\"\\\"\", \"\", text)\n",
    "    text = re.sub(r'[?|!|\\'|\"|#]',r'', text)\n",
    "    text = re.sub(r'[.|,|)|(|\\|/]',r' ', text)\n",
    "    text = remove_stopwords(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incorporate-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Title = train.Title.apply(lambda x: clean_text(x))\n",
    "test.Title = test.Title.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-brighton",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "grateful-owner",
   "metadata": {},
   "source": [
    "## 2.4 Clean Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "expired-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "potential-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['body_notag'] = train.Body.apply(lambda s: re.sub('<[^>]+>', '', s))\n",
    "test['body_notag'] = test.Body.apply(lambda s: re.sub('<[^>]+>', '', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "innocent-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.body_notag = train.body_notag.apply(lambda x: clean_text(x))\n",
    "test.body_notag = test.body_notag.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-third",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "basic-constraint",
   "metadata": {},
   "source": [
    "## 2.5 Combine Body and Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "listed-overview",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['all_text'] = train.Title + ' ' + train.body_notag\n",
    "test['all_text'] = test.Title + ' ' + test.body_notag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-thread",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "divided-shanghai",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-verse",
   "metadata": {},
   "source": [
    "## 3.1. Length of the Title & Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "reserved-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['title_length'] = train.Title.apply(lambda x: len(x.split()))\n",
    "test['title_length'] = test.Title.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stable-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['body_length'] = train.body_notag.apply(lambda x: len(x.split()))\n",
    "test['body_length'] = test.body_notag.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-richmond",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-assistant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "rural-shirt",
   "metadata": {},
   "source": [
    "# 4. Train-Val-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "promotional-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "saved-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45000 * 0.22222222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "suffering-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, _, _ = train_test_split(train, train['Y'], test_size=0.22222222, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "removed-moore",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35000, 11), (10000, 11))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "white-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_df, open('../data/processed/train_df.pkl', 'wb'))\n",
    "pickle.dump(val_df, open('../data/processed/val_df.pkl', 'wb'))\n",
    "pickle.dump(test, open('../data/processed/test_df.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-denmark",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
